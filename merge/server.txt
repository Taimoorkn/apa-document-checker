// File: c:\Users\Taimoor\Documents\GitHub\apa-document-checker\server\index.js
// server/index.js - Fixed router import
const express = require('express');
const cors = require('cors');
const helmet = require('helmet');
const path = require('path');
const fs = require('fs').promises;

const app = express();
const PORT = process.env.PORT || 3001;

// Security middleware
app.use(helmet({
  crossOriginEmbedderPolicy: false, // Needed for file uploads
}));

// CORS configuration
app.use(cors({
  origin: process.env.NODE_ENV === 'production' 
    ? ['https://your-domain.com'] // Replace with your domain
    : ['http://localhost:3000', 'http://127.0.0.1:3000'],
  credentials: true,
  methods: ['GET', 'POST', 'PUT', 'DELETE', 'OPTIONS'],
  allowedHeaders: ['Content-Type', 'Authorization', 'Accept']
}));

// Body parsing middleware
app.use(express.json({ limit: '50mb' }));
app.use(express.urlencoded({ extended: true, limit: '50mb' }));

// Create uploads directory if it doesn't exist
const uploadsDir = path.join(__dirname, 'uploads');
fs.mkdir(uploadsDir, { recursive: true }).catch(console.error);

// Health check endpoint
app.get('/api/health', (req, res) => {
  res.json({ 
    status: 'healthy', 
    timestamp: new Date().toISOString(),
    service: 'APA Document Checker Server'
  });
});

// Import and use document processing routes - FIXED
const docxRoutes = require('./routes/docx');
app.use('/api', docxRoutes);

// Error handling middleware
app.use((error, req, res, next) => {
  console.error('Server Error:', error);
  
  // Handle multer errors (file upload errors)
  if (error.code === 'LIMIT_FILE_SIZE') {
    return res.status(413).json({
      success: false,
      error: 'File too large. Maximum size is 10MB.',
      code: 'FILE_TOO_LARGE'
    });
  }
  
  if (error.code === 'LIMIT_UNEXPECTED_FILE') {
    return res.status(400).json({
      success: false,
      error: 'Unexpected file field. Please upload a DOCX file.',
      code: 'UNEXPECTED_FILE'
    });
  }
  
  // Handle other errors
  res.status(500).json({
    success: false,
    error: 'Internal server error',
    message: process.env.NODE_ENV === 'development' ? error.message : 'Something went wrong',
    code: 'INTERNAL_ERROR'
  });
});

// 404 handler for API routes
app.use('/api/*', (req, res) => {
  res.status(404).json({
    success: false,
    error: 'API endpoint not found',
    code: 'NOT_FOUND'
  });
});

// Start server
app.listen(PORT, (err) => {
  if (err) {
    console.error('Failed to start server:', err);
    process.exit(1);
  }
  
  console.log(`🚀 Server running on port ${PORT}`); 
});

// Graceful shutdown
process.on('SIGTERM', () => {
  console.log('SIGTERM received, shutting down gracefully');
  process.exit(0);
});

process.on('SIGINT', () => {
  console.log('SIGINT received, shutting down gracefully');  
  process.exit(0);
});

module.exports = app;



// File: c:\Users\Taimoor\Documents\GitHub\apa-document-checker\server\processors\DocxModifier.js
// server/processors/DocxModifier.js - DOCX modification for APA fixes (Memory-based)
const PizZip = require('pizzip');

class DocxModifier {
  constructor() {
    this.supportedFixes = [
      // Formatting fixes (DOCX modification)
      'fixFont', 'fixFontSize', 'fixLineSpacing', 'fixMargins', 'fixIndentation',
      // Content fixes (text replacement in XML)
      'addCitationComma', 'fixParentheticalConnector', 'fixEtAlFormatting', 
      'fixReferenceConnector', 'fixAllCapsHeading', 'addPageNumber'
    ];
  }

  /**
   * Apply formatting fix to a DOCX buffer by modifying the document structure
   */
  async applyFormattingFix(inputBuffer, fixAction, fixValue) {
    try {
      console.log(`🔧 DocxModifier.applyFormattingFix called with:`, {
        bufferSize: inputBuffer?.length,
        fixAction,
        fixValueType: typeof fixValue,
        fixValueKeys: typeof fixValue === 'object' ? Object.keys(fixValue || {}) : 'N/A'
      });
      
      if (!inputBuffer || inputBuffer.length === 0) {
        throw new Error('Invalid or empty input buffer provided');
      }
      
      // Create zip from buffer
      console.log('📦 Creating PizZip from buffer...');
      const zip = new PizZip(inputBuffer);
      console.log('✅ PizZip created successfully');
      
      // Apply the specific fix by modifying document XML
      const modifiedZip = await this.modifyDocumentXML(zip, fixAction, fixValue);
      
      // Generate the modified DOCX buffer
      const outputBuffer = modifiedZip.generate({
        type: 'nodebuffer',
        compression: 'DEFLATE'
      });
      
      return { success: true, buffer: outputBuffer };
      
    } catch (error) {
      console.error('Error modifying DOCX:', error);
      return { success: false, error: error.message };
    }
  }

  /**
   * Modify the document XML to apply formatting fixes
   */
  async modifyDocumentXML(zip, fixAction, fixValue) {
    try {
      console.log(`🔄 ModifyDocumentXML called with fixAction: ${fixAction}`);
      
      // Get the main document XML
      const docXmlFile = zip.file('word/document.xml');
      if (!docXmlFile) {
        throw new Error('Could not find document.xml in DOCX file');
      }
      
      console.log('📄 Found document.xml, reading content...');
      // Read document content using the correct PizZip API
      let documentContent = docXmlFile.asText();
      console.log(`📄 Document XML content length: ${documentContent.length} characters`);
      
      // Apply specific formatting fixes
      switch (fixAction) {
        case 'fixFont':
          documentContent = this.fixFontFamily(documentContent, fixValue || 'Times New Roman');
          break;
          
        case 'fixFontSize':
          documentContent = this.fixFontSize(documentContent, fixValue || 24); // 24 half-points = 12pt
          break;
          
        case 'fixLineSpacing':
          documentContent = this.fixLineSpacing(documentContent, fixValue || 480); // 480 = double spacing
          break;

        // Text-based content fixes
        case 'addCitationComma':
          documentContent = this.fixTextContent(documentContent, fixValue);
          break;
          
        case 'fixParentheticalConnector':
          documentContent = this.fixTextContent(documentContent, fixValue);
          break;
          
        case 'fixEtAlFormatting':
          documentContent = this.fixTextContent(documentContent, fixValue);
          break;
          
        case 'fixReferenceConnector':
          documentContent = this.fixTextContent(documentContent, fixValue);
          break;
          
        case 'fixAllCapsHeading':
          documentContent = this.fixTextContent(documentContent, fixValue);
          break;
          
        case 'addPageNumber':
          documentContent = this.fixTextContent(documentContent, fixValue);
          break;
          
        default:
          console.warn(`Unsupported fix action: ${fixAction}`);
          return zip; // Return unchanged if fix not supported
      }
      
      // Update the document XML in the zip
      zip.file('word/document.xml', documentContent);
      
      // Also modify styles.xml if it exists for document-wide changes
      const stylesXmlFile = zip.file('word/styles.xml');
      if (stylesXmlFile && ['fixFont', 'fixFontSize', 'fixLineSpacing'].includes(fixAction)) {
        let stylesContent = stylesXmlFile.asText();
        stylesContent = this.modifyStyles(stylesContent, fixAction, fixValue);
        zip.file('word/styles.xml', stylesContent);
      }
      
      return zip;
      
    } catch (error) {
      console.error('Error modifying document XML:', error);
      throw error;
    }
  }

  /**
   * Fix font family in document XML
   */
  fixFontFamily(xmlContent, fontFamily) {
    
    // Replace all font family references in run properties
    // Pattern matches: <w:rFonts w:ascii="..." w:hAnsi="..." ... />
    xmlContent = xmlContent.replace(
      /<w:rFonts[^>]*w:ascii="[^"]*"([^>]*)/g,
      `<w:rFonts w:ascii="${fontFamily}"$1`
    );
    
    xmlContent = xmlContent.replace(
      /<w:rFonts[^>]*w:hAnsi="[^"]*"([^>]*)/g,
      (match, rest) => match.replace(/w:hAnsi="[^"]*"/, `w:hAnsi="${fontFamily}"`)
    );
    
    // Add font family to runs that don't have it
    xmlContent = xmlContent.replace(
      /<w:rPr>(?![^<]*<w:rFonts)/g,
      `<w:rPr><w:rFonts w:ascii="${fontFamily}" w:hAnsi="${fontFamily}"/>`
    );
    
    return xmlContent;
  }

  /**
   * Fix font size in document XML
   */
  fixFontSize(xmlContent, halfPoints) {
    
    // Replace existing font size declarations
    xmlContent = xmlContent.replace(
      /<w:sz w:val="\d+"/g,
      `<w:sz w:val="${halfPoints}"`
    );
    
    xmlContent = xmlContent.replace(
      /<w:szCs w:val="\d+"/g,
      `<w:szCs w:val="${halfPoints}"`
    );
    
    // Add font size to runs that don't have it
    xmlContent = xmlContent.replace(
      /<w:rPr>(?![^<]*<w:sz)/g,
      `<w:rPr><w:sz w:val="${halfPoints}"/><w:szCs w:val="${halfPoints}"/>`
    );
    
    // Handle cases where rPr exists but doesn't have size
    xmlContent = xmlContent.replace(
      /<w:rPr>([^<]*(?:<w:(?!sz)[^>]*>[^<]*<\/w:[^>]*>)*[^<]*)<\/w:rPr>/g,
      (match, content) => {
        if (!content.includes('<w:sz')) {
          return `<w:rPr>${content}<w:sz w:val="${halfPoints}"/><w:szCs w:val="${halfPoints}"/></w:rPr>`;
        }
        return match;
      }
    );
    
    return xmlContent;
  }

  /**
   * Fix line spacing in document XML
   */
  fixLineSpacing(xmlContent, spacing) {
    
    // Replace existing spacing declarations in paragraph properties
    xmlContent = xmlContent.replace(
      /<w:spacing[^>]*w:line="\d+"[^>]*\/>/g,
      `<w:spacing w:line="${spacing}" w:lineRule="auto"/>`
    );
    
    // Add spacing to paragraphs that don't have it
    xmlContent = xmlContent.replace(
      /<w:pPr>(?![^<]*<w:spacing)/g,
      `<w:pPr><w:spacing w:line="${spacing}" w:lineRule="auto"/>`
    );
    
    return xmlContent;
  }

  /**
   * Modify styles.xml for document-wide formatting changes
   */
  modifyStyles(stylesContent, fixAction, fixValue) {
    
    try {
      switch (fixAction) {
        case 'fixFont':
          // Update the Normal style and other paragraph styles
          stylesContent = stylesContent.replace(
            /<w:rFonts[^>]*w:ascii="[^"]*"/g,
            `<w:rFonts w:ascii="${fixValue}"`
          );
          stylesContent = stylesContent.replace(
            /<w:rFonts[^>]*w:hAnsi="[^"]*"/g,
            (match) => match.replace(/w:hAnsi="[^"]*"/, `w:hAnsi="${fixValue}"`)
          );
          break;
          
        case 'fixFontSize':
          // Update default font sizes in styles
          stylesContent = stylesContent.replace(
            /<w:sz w:val="\d+"/g,
            `<w:sz w:val="${fixValue}"`
          );
          stylesContent = stylesContent.replace(
            /<w:szCs w:val="\d+"/g,
            `<w:szCs w:val="${fixValue}"`
          );
          break;
          
        case 'fixLineSpacing':
          // Update line spacing in paragraph styles
          stylesContent = stylesContent.replace(
            /<w:spacing[^>]*w:line="\d+"[^>]*\/>/g,
            `<w:spacing w:line="${fixValue}" w:lineRule="auto"/>`
          );
          break;
      }
      
      return stylesContent;
      
    } catch (error) {
      console.error('Error modifying styles:', error);
      return stylesContent; // Return unchanged if error
    }
  }

  /**
   * Fix text content in document XML (for citation and content fixes)
   */
  fixTextContent(xmlContent, fixValue) {
    try {
      if (!fixValue || !fixValue.originalText || !fixValue.replacementText) {
        console.warn('Invalid fixValue for text content fix:', fixValue);
        return xmlContent;
      }

      const { originalText, replacementText } = fixValue;
      
      console.log(`🔄 Replacing text in XML: "${originalText}" → "${replacementText}"`);
      
      // Simple and safe text replacement approach
      let modifiedContent = xmlContent;
      
      // Method 1: Replace the exact text as it appears in the XML
      // This handles most cases where text is within single w:t elements
      if (modifiedContent.includes(originalText)) {
        // IMPORTANT: Escape the replacement text for XML
        const xmlSafeReplacement = this.escapeXml(replacementText);
        modifiedContent = modifiedContent.replace(new RegExp(this.escapeRegex(originalText), 'g'), xmlSafeReplacement);
        console.log('✅ Direct text replacement successful with XML escaping');
        console.log(`📝 Replaced: "${originalText}" → "${xmlSafeReplacement}"`);
        return modifiedContent;
      }
      
      // Method 2: Replace text within w:t tags (handling XML structure)
      const escapedReplacement = this.escapeXml(replacementText);
      
      const replaced = modifiedContent.replace(
        new RegExp(`(<w:t[^>]*>)([^<]*${this.escapeRegex(originalText)}[^<]*)(</w:t>)`, 'g'),
        (match, openTag, textContent, closeTag) => {
          const newTextContent = textContent.replace(new RegExp(this.escapeRegex(originalText), 'g'), escapedReplacement);
          return openTag + newTextContent + closeTag;
        }
      );
      
      if (replaced !== modifiedContent) {
        console.log('✅ XML-aware text replacement successful with XML escaping');
        console.log(`📝 Replaced within tags: "${originalText}" → "${escapedReplacement}"`);
        return replaced;
      }
      
      console.warn('⚠️ No text replacement occurred - text might span multiple elements');
      return modifiedContent;
      
    } catch (error) {
      console.error('Error in fixTextContent:', error);
      return xmlContent; // Return original content on error
    }
  }

  /**
   * Escape special regex characters
   */
  escapeRegex(text) {
    if (!text || typeof text !== 'string') {
      return '';
    }
    return text.replace(/[.*+?^${}()|[\]\\]/g, '\\$&');
  }

  /**
   * Escape XML special characters
   */
  escapeXml(text) {
    return text
      .replace(/&/g, '&amp;')
      .replace(/</g, '&lt;')
      .replace(/>/g, '&gt;')
      .replace(/"/g, '&quot;')
      .replace(/'/g, '&#39;');
  }

  /**
   * Check if a fix action is supported
   */
  isFixSupported(fixAction) {
    return this.supportedFixes.includes(fixAction);
  }
}

module.exports = DocxModifier;

// File: c:\Users\Taimoor\Documents\GitHub\apa-document-checker\server\processors\XmlDocxProcessor.js
// server/processors/XmlDocxProcessor.js - XML-based DOCX processor using xml2js and PizZip
const PizZip = require('pizzip');
const xml2js = require('xml2js');
const fs = require('fs').promises;
const path = require('path');

class XmlDocxProcessor {
  constructor() {
    this.parser = new xml2js.Parser({
      explicitArray: false,
      ignoreAttrs: false,
      mergeAttrs: false,
      explicitCharkey: true
    });

    // APA formatting standards for comparison
    this.apaStandards = {
      font: { family: 'Times New Roman', size: 12 },
      spacing: { line: 2.0 },
      margins: { top: 1.0, bottom: 1.0, left: 1.0, right: 1.0 },
      indentation: { firstLine: 0.5 }
    };
  }

  /**
   * Process a DOCX document buffer and extract all necessary data
   */
  async processDocumentBuffer(buffer, filename = 'document.docx') {
    const tempFilePath = path.join(require('os').tmpdir(), `temp_${Date.now()}_${filename}`);
    
    try {
      // Write buffer to temporary file for processing
      await fs.writeFile(tempFilePath, buffer);
      
      // Process the temporary file
      const result = await this.processDocument(tempFilePath);
      
      return result;
    } finally {
      // Clean up temporary file
      try {
        await fs.unlink(tempFilePath);
      } catch (error) {
        console.warn('Could not clean up temporary file:', tempFilePath, error.message);
      }
    }
  }

  /**
   * Main processing function using xml2js and PizZip
   */
  async processDocument(filePath) {
    try {
      console.log('Starting XML-based DOCX processing for:', filePath);
      
      const buffer = await fs.readFile(filePath);
      
      // Load DOCX as ZIP archive
      const zip = new PizZip(buffer);
      
      // Extract document structure
      const documentData = await this.extractDocumentXml(zip);
      const stylesData = await this.extractStylesXml(zip);
      const settingsData = await this.extractSettingsXml(zip);
      
      // Process the extracted XML data
      const textResult = this.extractPlainText(documentData);
      const htmlResult = this.convertToHtml(documentData, stylesData);
      const formattingInfo = this.extractFormattingDetails(documentData, stylesData, settingsData);
      const structure = this.extractDocumentStructure(documentData);
      const styles = this.processStyles(stylesData);
      
      console.log('XML-based DOCX processing completed successfully');
      
      return {
        html: htmlResult,
        text: textResult,
        formatting: formattingInfo,
        structure: structure,
        styles: styles,
        messages: [{
          type: 'info',
          message: 'Document processed using XML parser for accurate structure extraction'
        }],
        processingInfo: {
          timestamp: new Date().toISOString(),
          fileSize: buffer.length,
          wordCount: textResult.split(/\s+/).filter(Boolean).length,
          processor: 'XmlDocxProcessor'
        }
      };
      
    } catch (error) {
      console.error('Error processing DOCX with XML parser:', error);
      throw new Error(`XML document processing failed: ${error.message}`);
    }
  }

  /**
   * Extract and parse document.xml
   */
  async extractDocumentXml(zip) {
    const docXmlFile = zip.file('word/document.xml');
    if (!docXmlFile) {
      throw new Error('document.xml not found in DOCX file');
    }
    
    const xmlContent = docXmlFile.asText();
    return await this.parser.parseStringPromise(xmlContent);
  }

  /**
   * Extract and parse styles.xml
   */
  async extractStylesXml(zip) {
    const stylesFile = zip.file('word/styles.xml');
    if (!stylesFile) {
      return null;
    }
    
    const xmlContent = stylesFile.asText();
    return await this.parser.parseStringPromise(xmlContent);
  }

  /**
   * Extract and parse settings.xml
   */
  async extractSettingsXml(zip) {
    const settingsFile = zip.file('word/settings.xml');
    if (!settingsFile) {
      return null;
    }
    
    const xmlContent = settingsFile.asText();
    return await this.parser.parseStringPromise(xmlContent);
  }

  /**
   * Extract plain text from document XML
   */
  extractPlainText(documentData) {
    try {
      let text = '';
      const body = documentData['w:document']['w:body'];
      const paragraphs = this.ensureArray(body['w:p']);
      
      paragraphs.forEach((para) => {
        if (!para) return;
        
        const runs = this.ensureArray(para['w:r']);
        runs.forEach(run => {
          if (run && run['w:t']) {
            const textElements = this.ensureArray(run['w:t']);
            textElements.forEach(t => {
              if (typeof t === 'string') {
                text += t;
              } else if (t._ !== undefined) {
                text += t._;
              }
            });
          }
        });
        text += '\n';
      });
      
      return text.trim();
      
    } catch (error) {
      console.error('Error extracting plain text:', error);
      return 'Text extraction failed';
    }
  }

  /**
   * Convert document XML to HTML with proper formatting
   */
  convertToHtml(documentData, stylesData) {
    try {
      let html = '<div class="docx-document">';
      
      const body = documentData['w:document']['w:body'];
      const paragraphs = this.ensureArray(body['w:p']);
      
      paragraphs.forEach((para, index) => {
        if (!para) return;
        
        // Extract paragraph properties
        const pPr = para['w:pPr'] || {};
        const paraStyle = this.extractParagraphStyle(pPr);
        
        // Check if this is a heading
        const isHeading = this.isHeadingParagraph(pPr);
        const tag = isHeading ? this.getHeadingTag(pPr) : 'p';
        
        html += `<${tag} data-para-index="${index}" style="${paraStyle}">`;
        
        // Process runs within paragraph
        const runs = this.ensureArray(para['w:r']);
        runs.forEach((run, runIndex) => {
          if (!run) return;
          
          const runStyle = this.extractRunStyle(run['w:rPr'] || {});
          const runText = this.extractRunText(run);
          
          if (runText) {
            html += `<span data-run-index="${runIndex}" style="${runStyle}">${this.escapeHtml(runText)}</span>`;
          }
        });
        
        html += `</${tag}>`;
      });
      
      html += '</div>';
      return html;
      
    } catch (error) {
      console.error('Error converting to HTML:', error);
      return '<div class="error">HTML conversion failed</div>';
    }
  }

  /**
   * Extract detailed formatting information
   */
  extractFormattingDetails(documentData, stylesData, settingsData) {
    const formatting = {
      document: {
        font: { family: null, size: null },
        spacing: { line: null, paragraph: null },
        margins: { top: null, bottom: null, left: null, right: null },
        indentation: { firstLine: null, hanging: null },
        pageSetup: {}
      },
      paragraphs: [],
      runs: [],
      compliance: {}
    };
    
    try {
      const body = documentData['w:document']['w:body'];
      
      // Extract page setup and margins from sectPr
      const sectPr = body['w:sectPr'];
      if (sectPr) {
        this.extractPageMargins(sectPr, formatting);
        this.extractPageSetup(sectPr, formatting);
      }
      
      // Extract paragraph-level formatting
      const paragraphs = this.ensureArray(body['w:p']);
      
      paragraphs.forEach((para, index) => {
        if (!para) return;
        
        const paraFormatting = this.extractParagraphFormatting(para, index);
        formatting.paragraphs.push(paraFormatting);
      });
      
      // Set document-level defaults
      this.setDocumentDefaults(formatting);
      
      // Calculate APA compliance
      formatting.compliance = this.calculateAPACompliance(formatting);
      
    } catch (error) {
      console.error('Error extracting formatting details:', error);
    }
    
    return formatting;
  }

  /**
   * Extract document structure (headings, citations, etc.)
   */
  extractDocumentStructure(documentData) {
    const structure = {
      headings: [],
      sections: [],
      citations: [],
      references: [],
      tables: [],
      figures: []
    };
    
    try {
      const body = documentData['w:document']['w:body'];
      const paragraphs = this.ensureArray(body['w:p']);
      
      paragraphs.forEach((para, index) => {
        if (!para) return;
        
        const text = this.extractParagraphText(para);
        if (!text.trim()) return;
        
        // Detect headings
        if (this.isHeadingParagraph(para['w:pPr'])) {
          const level = this.getHeadingLevel(para['w:pPr']);
          structure.headings.push({
            text: text.trim(),
            level: level,
            paragraphIndex: index
          });
        }
        
        // Detect citations
        this.extractCitations(text, index, structure.citations);
        
        // Detect special sections
        this.detectSpecialSections(text, index, structure.sections);
        
        // Detect reference entries
        this.detectReferenceEntries(text, index, structure);
      });
      
    } catch (error) {
      console.error('Error extracting document structure:', error);
    }
    
    return structure;
  }

  /**
   * Helper methods
   */
  
  ensureArray(item) {
    if (!item) return [];
    return Array.isArray(item) ? item : [item];
  }

  extractParagraphStyle(pPr) {
    let style = '';
    
    // Line spacing
    if (pPr['w:spacing'] && pPr['w:spacing'].$) {
      const spacing = pPr['w:spacing'].$;
      if (spacing['w:line']) {
        const lineHeight = this.lineSpacingToDecimal(spacing['w:line'], spacing['w:lineRule']);
        style += `line-height: ${lineHeight}; `;
      }
    }
    
    // Indentation
    if (pPr['w:ind'] && pPr['w:ind'].$) {
      const ind = pPr['w:ind'].$;
      if (ind['w:firstLine']) {
        const indent = this.twipsToInches(parseInt(ind['w:firstLine']));
        style += `text-indent: ${indent}in; `;
      }
    }
    
    // Alignment
    if (pPr['w:jc'] && pPr['w:jc'].$) {
      const align = pPr['w:jc'].$['w:val'];
      const cssAlign = this.wordAlignToCss(align);
      style += `text-align: ${cssAlign}; `;
    }
    
    return style;
  }

  extractRunStyle(rPr) {
    let style = '';
    
    // Font family
    if (rPr['w:rFonts'] && rPr['w:rFonts'].$) {
      const fontFamily = rPr['w:rFonts'].$['w:ascii'] || rPr['w:rFonts'].$['w:hAnsi'];
      if (fontFamily) {
        style += `font-family: "${fontFamily}", serif; `;
      }
    }
    
    // Font size
    if (rPr['w:sz'] && rPr['w:sz'].$) {
      const fontSize = parseInt(rPr['w:sz'].$['w:val']) / 2;
      style += `font-size: ${fontSize}pt; `;
    }
    
    // Bold
    if (rPr['w:b']) {
      style += 'font-weight: bold; ';
    }
    
    // Italic
    if (rPr['w:i']) {
      style += 'font-style: italic; ';
    }
    
    // Underline
    if (rPr['w:u']) {
      style += 'text-decoration: underline; ';
    }
    
    // Color
    if (rPr['w:color'] && rPr['w:color'].$) {
      const color = rPr['w:color'].$['w:val'];
      if (color && color !== 'auto') {
        style += `color: #${color}; `;
      }
    }
    
    return style;
  }

  extractRunText(run) {
    let text = '';
    
    // Process all child elements in order
    if (run) {
      const children = Object.keys(run);
      children.forEach(key => {
        if (key === 'w:t') {
          // Text content
          const textElements = this.ensureArray(run['w:t']);
          textElements.forEach(t => {
            if (typeof t === 'string') {
              text += t;
            } else if (t._ !== undefined) {
              text += t._;
            }
          });
        } else if (key === 'w:br') {
          // Line breaks - preserve them as actual breaks
          text += '\n';
        } else if (key === 'w:cr') {
          // Carriage returns
          text += '\n';
        } else if (key === 'w:tab') {
          // Tabs
          text += '\t';
        }
      });
    }
    
    return text;
  }

  extractParagraphText(para) {
    let text = '';
    const runs = this.ensureArray(para['w:r']);
    
    runs.forEach(run => {
      text += this.extractRunText(run);
    });
    
    return text;
  }

  isHeadingParagraph(pPr) {
    if (!pPr || !pPr['w:pStyle']) return false;
    
    const styleName = pPr['w:pStyle'].$?.['w:val'] || '';
    return /heading|title/i.test(styleName);
  }

  getHeadingTag(pPr) {
    if (!pPr || !pPr['w:pStyle']) return 'p';
    
    const styleName = pPr['w:pStyle'].$?.['w:val'] || '';
    const match = styleName.match(/heading(\d+)/i);
    
    if (match) {
      const level = Math.min(6, Math.max(1, parseInt(match[1])));
      return `h${level}`;
    }
    
    return styleName.toLowerCase().includes('title') ? 'h1' : 'p';
  }

  getHeadingLevel(pPr) {
    if (!pPr || !pPr['w:pStyle']) return 1;
    
    const styleName = pPr['w:pStyle'].$?.['w:val'] || '';
    const match = styleName.match(/heading(\d+)/i);
    
    return match ? parseInt(match[1]) : 1;
  }

  extractCitations(text, paragraphIndex, citations) {
    const citationPattern = /\(([^)]+),\s*(\d{4})[^)]*\)/g;
    let match;
    
    while ((match = citationPattern.exec(text)) !== null) {
      citations.push({
        text: match[0],
        author: match[1],
        year: match[2],
        paragraphIndex: paragraphIndex,
        position: match.index
      });
    }
  }

  detectSpecialSections(text, index, sections) {
    const textLower = text.toLowerCase().trim();
    
    if (textLower === 'references' || textLower === 'bibliography') {
      sections.push({
        type: 'references',
        startIndex: index,
        title: text
      });
    } else if (textLower === 'abstract') {
      sections.push({
        type: 'abstract',
        startIndex: index,
        title: text
      });
    } else if (textLower.includes('method') && text.length < 50) {
      sections.push({
        type: 'method',
        startIndex: index,
        title: text
      });
    }
  }

  detectReferenceEntries(text, index, structure) {
    const referencesSection = structure.sections.find(s => s.type === 'references');
    if (referencesSection && index > referencesSection.startIndex) {
      if (text.match(/^[A-Z][a-zA-Z-']+,\s+[A-Z].*\(\d{4}\)/)) {
        structure.references.push({
          text: text.trim(),
          paragraphIndex: index,
          type: this.detectReferenceType(text)
        });
      }
    }
  }

  detectReferenceType(text) {
    if (text.match(/\b(?:journal|quarterly|review|proceedings|bulletin)\b/i)) {
      return 'journal';
    }
    if (text.match(/\b(?:publisher|press|books|publication)\b/i)) {
      return 'book';
    }
    if (text.match(/\b(?:http|www\.|\.com|\.org|\.edu|retrieved)\b/i)) {
      return 'website';
    }
    if (text.match(/\b(?:in\s+[A-Z]|\(eds?\.\)|\(ed\.\))\b/i)) {
      return 'chapter';
    }
    return 'unknown';
  }

  // Utility conversion methods
  twipsToInches(twips) {
    return twips / 1440;
  }

  twipsToPoints(twips) {
    return twips / 20;
  }

  lineSpacingToDecimal(value, rule) {
    if (rule === 'auto') {
      return value / 240;
    } else if (rule === 'atLeast' || rule === 'exact') {
      return this.twipsToPoints(value) / 12;
    }
    return 2.0; // Default double spacing
  }

  wordAlignToCss(align) {
    const alignMap = {
      'left': 'left',
      'center': 'center', 
      'right': 'right',
      'both': 'justify',
      'justify': 'justify'
    };
    return alignMap[align] || 'left';
  }

  escapeHtml(text) {
    const div = { innerHTML: '' };
    const textNode = { textContent: text };
    return text
      .replace(/&/g, '&amp;')
      .replace(/</g, '&lt;')
      .replace(/>/g, '&gt;')
      .replace(/"/g, '&quot;')
      .replace(/'/g, '&#39;');
  }

  // Additional helper methods for formatting extraction
  extractPageMargins(sectPr, formatting) {
    const pgMar = sectPr['w:pgMar'];
    if (pgMar && pgMar.$) {
      formatting.document.margins = {
        top: this.twipsToInches(parseInt(pgMar.$['w:top'] || 0)),
        bottom: this.twipsToInches(parseInt(pgMar.$['w:bottom'] || 0)),
        left: this.twipsToInches(parseInt(pgMar.$['w:left'] || 0)),
        right: this.twipsToInches(parseInt(pgMar.$['w:right'] || 0))
      };
    }
  }

  extractPageSetup(sectPr, formatting) {
    const pgSz = sectPr['w:pgSz'];
    if (pgSz && pgSz.$) {
      formatting.document.pageSetup = {
        width: this.twipsToInches(parseInt(pgSz.$['w:w'] || 0)),
        height: this.twipsToInches(parseInt(pgSz.$['w:h'] || 0)),
        orientation: pgSz.$['w:orient'] || 'portrait'
      };
    }
  }

  extractParagraphFormatting(para, index) {
    const paraText = this.extractParagraphText(para);
    const paraFormatting = {
      index,
      text: paraText,
      font: { family: null, size: null, bold: false, italic: false },
      spacing: { line: null, before: null, after: null },
      indentation: { firstLine: null, hanging: null, left: null, right: null },
      alignment: null,
      style: null,
      runs: []
    };

    // Debug paragraph extraction
    if (process.env.NODE_ENV === 'development') {
    }

    // Extract paragraph properties
    const pPr = para['w:pPr'];
    if (pPr) {
      // Style
      if (pPr['w:pStyle'] && pPr['w:pStyle'].$) {
        paraFormatting.style = pPr['w:pStyle'].$['w:val'];
      }

      // Spacing
      if (pPr['w:spacing'] && pPr['w:spacing'].$) {
        const spacing = pPr['w:spacing'].$;
        paraFormatting.spacing = {
          line: spacing['w:line'] ? this.lineSpacingToDecimal(spacing['w:line'], spacing['w:lineRule']) : 2.0,
          before: spacing['w:before'] ? this.twipsToPoints(parseInt(spacing['w:before'])) : null,
          after: spacing['w:after'] ? this.twipsToPoints(parseInt(spacing['w:after'])) : null
        };
      }

      // Indentation
      if (pPr['w:ind'] && pPr['w:ind'].$) {
        const ind = pPr['w:ind'].$;
        paraFormatting.indentation = {
          firstLine: ind['w:firstLine'] ? this.twipsToInches(parseInt(ind['w:firstLine'])) : null,
          hanging: ind['w:hanging'] ? this.twipsToInches(parseInt(ind['w:hanging'])) : null,
          left: ind['w:left'] ? this.twipsToInches(parseInt(ind['w:left'])) : null,
          right: ind['w:right'] ? this.twipsToInches(parseInt(ind['w:right'])) : null
        };
      }

      // Alignment
      if (pPr['w:jc'] && pPr['w:jc'].$) {
        paraFormatting.alignment = pPr['w:jc'].$['w:val'];
      }
    }

    // Extract run-level formatting
    const runs = this.ensureArray(para['w:r']);
    runs.forEach((run, runIndex) => {
      if (!run) return;

      const runFormatting = {
        index: runIndex,
        text: this.extractRunText(run),
        font: { family: null, size: null, bold: false, italic: false, underline: false },
        color: null
      };

      const rPr = run['w:rPr'];
      if (rPr) {
        // Font
        const rFonts = rPr['w:rFonts'];
        if (rFonts && rFonts.$) {
          runFormatting.font.family = rFonts.$['w:ascii'] || rFonts.$['w:hAnsi'] || null;
        }

        // Size - convert from Word's half-points to points
        const sz = rPr['w:sz'];
        if (sz && sz.$) {
          const rawValue = parseInt(sz.$['w:val']);
          runFormatting.font.size = rawValue / 2; // Convert from half-points to points
        }

        // Formatting - check for existence of elements, not their values
        runFormatting.font.bold = 'w:b' in rPr;
        runFormatting.font.italic = 'w:i' in rPr;
        runFormatting.font.underline = 'w:u' in rPr;
        

        // Color
        const color = rPr['w:color'];
        if (color && color.$) {
          runFormatting.color = color.$['w:val'];
        }
      }

      paraFormatting.runs.push(runFormatting);
    });

    // Set paragraph font from first run if available
    if (paraFormatting.runs.length > 0) {
      const firstRun = paraFormatting.runs[0];
      if (firstRun.font.family && !paraFormatting.font.family) {
        paraFormatting.font.family = firstRun.font.family;
      }
      if (firstRun.font.size && !paraFormatting.font.size) {
        paraFormatting.font.size = firstRun.font.size;
      }
    }

    return paraFormatting;
  }

  setDocumentDefaults(formatting) {
    if (formatting.paragraphs.length > 0) {
      const firstPara = formatting.paragraphs.find(p => p.font.family && p.font.size) || formatting.paragraphs[0];
      
      formatting.document.font = { 
        family: firstPara.font.family || null,
        size: firstPara.font.size || null
      };
      
      formatting.document.spacing.line = firstPara.spacing.line || null;
      formatting.document.indentation = { 
        firstLine: firstPara.indentation.firstLine || null,
        hanging: firstPara.indentation.hanging || null 
      };
    }
  }

  processStyles(stylesData) {
    if (!stylesData) {
      return { styles: [], defaultStyle: null };
    }

    const styles = [];
    const stylesRoot = stylesData['w:styles'];
    
    if (stylesRoot && stylesRoot['w:style']) {
      const styleElements = this.ensureArray(stylesRoot['w:style']);
      
      styleElements.forEach(style => {
        if (style && style.$) {
          const styleInfo = {
            id: style.$.styleId,
            name: style['w:name'] ? style['w:name'].$['w:val'] : style.$.styleId,
            type: style.$.type,
            isDefault: style.$.default === '1',
            formatting: {}
          };
          
          // Extract paragraph properties
          const pPr = style['w:pPr'];
          const rPr = style['w:rPr'];
          
          if (pPr) {
            if (pPr['w:spacing'] && pPr['w:spacing'].$) {
              styleInfo.formatting.spacing = pPr['w:spacing'].$;
            }
            if (pPr['w:ind'] && pPr['w:ind'].$) {
              styleInfo.formatting.indentation = pPr['w:ind'].$;
            }
          }
          
          if (rPr) {
            if (rPr['w:rFonts'] && rPr['w:rFonts'].$) {
              styleInfo.formatting.font = rPr['w:rFonts'].$;
            }
            if (rPr['w:sz'] && rPr['w:sz'].$) {
              styleInfo.formatting.fontSize = parseInt(rPr['w:sz'].$['w:val']) / 2;
            }
          }
          
          styles.push(styleInfo);
        }
      });
    }
    
    const defaultStyle = styles.find(s => s.isDefault && s.type === 'paragraph') || 
                        styles.find(s => s.name === 'Normal') ||
                        null;
    
    return { styles, defaultStyle };
  }

  calculateAPACompliance(formatting) {
    const compliance = {
      font: { family: false, size: false, score: 0 },
      spacing: { line: false, score: 0 },
      margins: { all: false, individual: {}, score: 0 },
      indentation: { firstLine: false, score: 0 },
      overall: 0
    };
    
    // Check font compliance
    if (formatting.document.font.family) {
      const fontFamily = formatting.document.font.family.toLowerCase();
      compliance.font.family = fontFamily.includes('times new roman') || 
                              fontFamily.includes('times') ||
                              fontFamily.includes('liberation serif');
    }
    
    if (formatting.document.font.size) {
      compliance.font.size = Math.abs(formatting.document.font.size - 12) < 0.5;
    }
    
    compliance.font.score = (compliance.font.family ? 50 : 0) + (compliance.font.size ? 50 : 0);
    
    // Check spacing compliance
    if (formatting.document.spacing.line) {
      compliance.spacing.line = Math.abs(formatting.document.spacing.line - 2.0) < 0.1;
      compliance.spacing.score = compliance.spacing.line ? 100 : 0;
    }
    
    // Check margins compliance
    if (formatting.document.margins) {
      let marginsCorrect = 0;
      Object.entries(formatting.document.margins).forEach(([side, value]) => {
        const isCorrect = value !== null && Math.abs(value - 1.0) < 0.1;
        compliance.margins.individual[side] = isCorrect;
        if (isCorrect) marginsCorrect++;
      });
      compliance.margins.all = marginsCorrect === 4;
      compliance.margins.score = (marginsCorrect / 4) * 100;
    }
    
    // Check indentation compliance
    const correctIndentation = formatting.paragraphs.filter(p => 
      p.indentation.firstLine !== null && Math.abs(p.indentation.firstLine - 0.5) < 0.05
    ).length;
    
    const totalParagraphs = formatting.paragraphs.filter(p => p.text.trim().length > 0).length;
    
    if (totalParagraphs > 0) {
      compliance.indentation.firstLine = correctIndentation / totalParagraphs > 0.8;
      compliance.indentation.score = (correctIndentation / totalParagraphs) * 100;
    }
    
    // Calculate overall compliance
    const scores = [
      compliance.font.score,
      compliance.spacing.score,
      compliance.margins.score,
      compliance.indentation.score
    ].filter(score => score !== null);
    
    compliance.overall = scores.length > 0 ? scores.reduce((a, b) => a + b) / scores.length : 0;
    
    return compliance;
  }
}

module.exports = XmlDocxProcessor;

// File: c:\Users\Taimoor\Documents\GitHub\apa-document-checker\server\routes\docx.js
// server/routes/docx.js - Ensure proper router export
const express = require('express');
const multer = require('multer');
const path = require('path');
const fs = require('fs').promises;
const os = require('os');
const XmlDocxProcessor = require('../processors/XmlDocxProcessor');
const DocxModifier = require('../processors/DocxModifier');

// Create router instance - IMPORTANT: This must be the default export
const router = express.Router();

// Configure multer for file uploads
const storage = multer.diskStorage({
  destination: (req, file, cb) => {
    cb(null, path.join(__dirname, '../uploads/'));
  },
  filename: (req, file, cb) => {
    // Generate unique filename with timestamp
    const uniqueSuffix = Date.now() + '-' + Math.round(Math.random() * 1E9);
    const extension = path.extname(file.originalname);
    cb(null, `document-${uniqueSuffix}${extension}`);
  }
});

// File filter to only allow DOCX files
const fileFilter = (req, file, cb) => {
  const allowedMimes = [
    'application/vnd.openxmlformats-officedocument.wordprocessingml.document',
    'application/octet-stream' // Some systems send DOCX as octet-stream
  ];
  
  const allowedExtensions = ['.docx'];
  const fileExtension = path.extname(file.originalname).toLowerCase();
  
  if (allowedMimes.includes(file.mimetype) || allowedExtensions.includes(fileExtension)) {
    cb(null, true);
  } else {
    cb(new Error('Only DOCX files are allowed'), false);
  }
};

const upload = multer({
  storage: storage,
  fileFilter: fileFilter,
  limits: {
    fileSize: 10 * 1024 * 1024, // 10MB limit
    files: 1 // Only one file at a time
  }
});

// Initialize processors - XML-based processing
const xmlDocxProcessor = new XmlDocxProcessor();
const docxModifier = new DocxModifier();

/**
 * POST /api/upload-docx
 * Upload and process a DOCX file
 */
router.post('/upload-docx', upload.single('document'), async (req, res) => {
  let filePath = null;
  
  try {
    // Validate file upload
    if (!req.file) {
      return res.status(400).json({
        success: false,
        error: 'No file uploaded',
        code: 'NO_FILE'
      });
    }
    
    filePath = req.file.path;
    console.log(`Processing uploaded file: ${req.file.originalname} (${req.file.size} bytes)`);
    
    // XML-based processing
    
    // Validate file exists and is readable
    try {
      await fs.access(filePath, fs.constants.R_OK);
    } catch (error) {
      throw new Error('Uploaded file is not readable');
    }
    
    // Additional DOCX validation - check file header
    const fileBuffer = await fs.readFile(filePath);
    if (!isValidDocxFile(fileBuffer)) {
      throw new Error('File is not a valid DOCX document');
    }
    
    // Process the document using XML parser
    console.log('Starting XML-based document processing...');
    const startTime = Date.now();
    
    const result = await xmlDocxProcessor.processDocument(filePath);
    const processorUsed = result.processingInfo?.processor || 'XmlDocxProcessor';
    
    const processingTime = Date.now() - startTime;
    console.log(`Document processing completed in ${processingTime}ms using ${processorUsed}`);
    
    // Add processing metadata
    result.processingInfo = {
      ...result.processingInfo,
      processingTime: processingTime,
      originalFilename: req.file.originalname,
      fileSize: req.file.size
      // No server file path - we're processing in memory only
    };
    
    // Validate processing results
    if (!result.text || !result.html) {
      throw new Error('Document processing produced incomplete results');
    }
    
    // Clean up uploaded file immediately since we're processing in memory
    await fs.unlink(filePath);
    filePath = null; // Mark as cleaned up
    
    // Return success response
    res.json({
      success: true,
      document: result,
      message: 'Document processed successfully'
    });
    
  } catch (error) {
    console.error('Error processing document:', error);
    
    // Clean up uploaded file if it exists
    if (filePath) {
      try {
        await fs.unlink(filePath);
      } catch (cleanupError) {
        console.error('Error cleaning up file:', cleanupError);
      }
    }
    
    // Determine error type and appropriate response
    let statusCode = 500;
    let errorCode = 'PROCESSING_ERROR';
    let errorMessage = 'Failed to process document';
    
    if (error.message.includes('not a valid DOCX')) {
      statusCode = 400;
      errorCode = 'INVALID_FILE';
      errorMessage = 'File is not a valid DOCX document';
    } else if (error.message.includes('DOCX processing failed')) {
      statusCode = 422;
      errorCode = 'PROCESSING_FAILED';
      errorMessage = 'Document could not be processed';
    } else if (error.message.includes('not readable')) {
      statusCode = 400;
      errorCode = 'FILE_UNREADABLE';
      errorMessage = 'Uploaded file could not be read';
    }
    
    res.status(statusCode).json({
      success: false,
      error: errorMessage,
      code: errorCode,
      details: process.env.NODE_ENV === 'development' ? error.message : undefined
    });
  }
});

/**
 * POST /api/apply-fix
 * Apply a formatting fix to a DOCX document (Memory-based processing)
 */
router.post('/apply-fix', async (req, res) => {
  console.log('🎯 /api/apply-fix endpoint called');
  console.log('Request method:', req.method);
  console.log('Request headers:', Object.keys(req.headers));
  console.log('Request content-type:', req.get('content-type'));
  console.log('Request body exists:', !!req.body);
  console.log('Request body size:', JSON.stringify(req.body || {}).length);
  
  try {
    // Parse JSON body manually if needed
    let requestData;
    
    console.log('Request body keys:', Object.keys(req.body || {}));
    console.log('Request body type:', typeof req.body);
    console.log('Is multipart:', req.is('multipart/form-data'));
    
    if (req.is('multipart/form-data')) {
      console.log('📦 Processing multipart form data');
      // Handle multipart data (document buffer + metadata)
      requestData = {
        fixAction: req.body.fixAction,
        fixValue: req.body.fixValue,
        originalFilename: req.body.originalFilename
      };
    } else {
      console.log('📦 Processing JSON data');
      // Handle JSON data with base64 document
      requestData = req.body;
    }
    
    console.log('Parsed requestData keys:', Object.keys(requestData || {}));
    
    const { documentBuffer, fixAction, fixValue, originalFilename } = requestData;
    
    // Validate input
    if (!documentBuffer || !fixAction) {
      return res.status(400).json({
        success: false,
        error: 'Missing required parameters: documentBuffer and fixAction',
        code: 'MISSING_PARAMS'
      });
    }
    
    // Check if the fix is supported
    if (!docxModifier.isFixSupported(fixAction)) {
      return res.status(400).json({
        success: false,
        error: `Unsupported fix action: ${fixAction}`,
        code: 'UNSUPPORTED_FIX'
      });
    }
    
    console.log(`🔧 Applying fix: ${fixAction} to document buffer`);
    console.log('Fix value:', JSON.stringify(fixValue, null, 2));
    
    // Convert base64 to buffer if needed
    let docxBuffer;
    if (typeof documentBuffer === 'string') {
      try {
        docxBuffer = Buffer.from(documentBuffer, 'base64');
        console.log(`✅ Buffer conversion successful, size: ${docxBuffer.length} bytes`);
      } catch (error) {
        return res.status(400).json({
          success: false,
          error: `Invalid base64 document buffer: ${error.message}`,
          code: 'INVALID_BUFFER'
        });
      }
    } else {
      docxBuffer = Buffer.from(documentBuffer);
    }
    
    // Apply the fix using DocxModifier (memory-based)
    console.log('🔄 Calling DocxModifier.applyFormattingFix...');
    const modificationResult = await docxModifier.applyFormattingFix(
      docxBuffer,
      fixAction, 
      fixValue
    );
    
    console.log('DocxModifier result:', {
      success: modificationResult.success,
      error: modificationResult.error,
      bufferSize: modificationResult.buffer?.length
    });
    
    if (!modificationResult.success) {
      return res.status(500).json({
        success: false,
        error: `Failed to apply fix: ${modificationResult.error}`,
        code: 'FIX_APPLICATION_FAILED',
        details: {
          fixAction,
          fixValue,
          originalError: modificationResult.error
        }
      });
    }
    
    console.log(`✅ Fix applied successfully, reprocessing document...`);
    
    // Reprocess the modified document buffer using XML processor
    console.log('Reprocessing with XML processor...');
    const startTime = Date.now();
    
    const reprocessingResult = await xmlDocxProcessor.processDocumentBuffer(modificationResult.buffer, originalFilename || 'document.docx');
    
    const processingTime = Date.now() - startTime;
    console.log(`Document reprocessing completed in ${processingTime}ms`);
    
    // Add processing metadata
    reprocessingResult.processingInfo = {
      ...reprocessingResult.processingInfo,
      processingTime: processingTime,
      originalFilename: originalFilename || 'unknown.docx',
      fixApplied: fixAction,
      fixValue: fixValue
    };
    
    // Return the reprocessed document with the modified buffer for further fixes
    res.json({
      success: true,
      document: reprocessingResult,
      modifiedDocumentBuffer: modificationResult.buffer.toString('base64'), // For next fix iteration
      fixApplied: fixAction,
      message: `Successfully applied ${fixAction} and reprocessed document`
    });
    
  } catch (error) {
    console.error('❌ Critical error in apply-fix route:', error);
    console.error('❌ Error stack:', error.stack);
    console.error('❌ Error details:', {
      name: error.name,
      message: error.message,
      code: error.code
    });
    
    // Ensure we always send a JSON response
    try {
      res.status(500).json({
        success: false,
        error: 'Failed to apply fix to document',
        code: 'APPLY_FIX_ERROR',
        details: process.env.NODE_ENV === 'development' ? {
          message: error.message,
          stack: error.stack,
          name: error.name
        } : undefined
      });
    } catch (responseError) {
      console.error('❌ Failed to send error response:', responseError);
      res.status(500).end('Internal server error');
    }
  }
});

/**
 * GET /api/processing-status
 * Health check for document processing capabilities
 */
router.get('/processing-status', async (req, res) => {
  // Check XML processor availability
  let xmlProcessorAvailable = true; // XML processing is always available
  let xmlProcessorError = null;
  
  try {
    // Test basic XML processing capability
    new XmlDocxProcessor();
  } catch (error) {
    xmlProcessorAvailable = false;
    xmlProcessorError = error.message;
  }
  
  res.json({
    success: true,
    status: 'operational',
    capabilities: {
      docxProcessing: xmlProcessorAvailable,
      xmlProcessing: xmlProcessorAvailable,
      formattingExtraction: xmlProcessorAvailable,
      structureAnalysis: xmlProcessorAvailable,
      apaCompliance: xmlProcessorAvailable
    },
    processors: {
      xmlProcessor: {
        available: xmlProcessorAvailable,
        error: xmlProcessorError,
        primary: true,
        required: true
      }
    },
    limits: {
      maxFileSize: '10MB',
      allowedFormats: ['DOCX'],
      processingTimeout: '30s'
    },
    timestamp: new Date().toISOString()
  });
});

/**
 * Helper function to validate DOCX file
 */
function isValidDocxFile(buffer) {
  try {
    // DOCX files are ZIP archives, so they start with PK (ZIP signature)
    if (buffer.length < 4) return false;
    
    // Check ZIP signature
    const zipSignature = buffer.slice(0, 4);
    const isZip = zipSignature[0] === 0x50 && zipSignature[1] === 0x4B;
    
    if (!isZip) return false;
    
    return true;
  } catch (error) {
    return false;
  }
}

/**
 * Error handling middleware specific to this router
 */
router.use((error, req, res, next) => {
  console.error('DOCX Router Error:', error);
  
  // Handle multer-specific errors
  if (error instanceof multer.MulterError) {
    if (error.code === 'LIMIT_FILE_SIZE') {
      return res.status(413).json({
        success: false,
        error: 'File too large (max 10MB)',
        code: 'FILE_TOO_LARGE'
      });
    }
    
    if (error.code === 'LIMIT_UNEXPECTED_FILE') {
      return res.status(400).json({
        success: false,
        error: 'Unexpected file field',
        code: 'UNEXPECTED_FILE'
      });
    }
    
    return res.status(400).json({
      success: false,
      error: error.message,
      code: 'UPLOAD_ERROR'
    });
  }
  
  // Handle file filter errors
  if (error.message === 'Only DOCX files are allowed') {
    return res.status(400).json({
      success: false,
      error: 'Only DOCX files are allowed',
      code: 'INVALID_FILE_TYPE'
    });
  }
  
  // Pass other errors to main error handler
  next(error);
});

// IMPORTANT: Export the router properly
module.exports = router;

